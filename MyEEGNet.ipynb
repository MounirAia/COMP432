{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "BIXI_X_asp0m",
        "6fN4EccxCtKH"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "nu8GmchU6wGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!git clone https://github.com/speechbrain/benchmarks\n",
        "%cd /content/benchmarks\n",
        "!git checkout eeg\n",
        "\n",
        "%cd /content/benchmarks/benchmarks/MOABB\n",
        "!pip install -r extra-requirements.txt # Install additional dependencies"
      ],
      "metadata": {
        "id": "SJrY-DlvWSKq"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Clone SpeechBrain repository (development branch)\n",
        "%cd /content/\n",
        "!git clone https://github.com/speechbrain/speechbrain/\n",
        "%cd /content/speechbrain/\n",
        "\n",
        "# Install required dependencies\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Install SpeechBrain in editable mode\n",
        "!pip install -e .\n",
        "\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "CG7ez3DdmfaD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## YAML"
      ],
      "metadata": {
        "id": "ctJiwFSMfm5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MyEEGNETYaml = \"\"\"\n",
        "seed: 1234\n",
        "__set_torchseed: !apply:torch.manual_seed [!ref <seed>]\n",
        "\n",
        "# DIRECTORIES\n",
        "data_folder: !PLACEHOLDER  #'/path/to/dataset'. The dataset will be automatically downloaded in this folder\n",
        "cached_data_folder: !PLACEHOLDER #'path/to/pickled/dataset'\n",
        "output_folder: !PLACEHOLDER #'path/to/results'\n",
        "\n",
        "# DATASET HPARS\n",
        "# Defining the MOABB dataset.\n",
        "dataset: !new:moabb.datasets.BNCI2014001\n",
        "save_prepared_dataset: True # set to True if you want to save the prepared dataset as a pkl file to load and use afterwards\n",
        "data_iterator_name: !PLACEHOLDER\n",
        "target_subject_idx: !PLACEHOLDER\n",
        "target_session_idx: !PLACEHOLDER\n",
        "events_to_load: null # all events will be loaded\n",
        "original_sample_rate: 250 # Original sampling rate provided by dataset authors\n",
        "sample_rate: 125 # Target sampling rate (Hz)\n",
        "# band-pass filtering cut-off frequencies\n",
        "fmin: 0.13\n",
        "fmax: 46.0\n",
        "n_classes: 4\n",
        "# tmin, tmax respect to stimulus onset that define the interval attribute of the dataset class\n",
        "# trial begins (0 s), cue (2 s, 1.25 s long); each trial is 6 s long\n",
        "# dataset interval starts from 2\n",
        "# -->tmin tmax are referred to this start value (e.g., tmin=0.5 corresponds to 2.5 s)\n",
        "tmin: 0.\n",
        "tmax: 4.0\n",
        "# number of steps used when selecting adjacent channels from a seed channel (default at Cz)\n",
        "n_steps_channel_selection: 2\n",
        "T: !apply:math.ceil\n",
        "    - !ref <sample_rate> * (<tmax> - <tmin>)\n",
        "C: 22\n",
        "# We here specify how to perfom test:\n",
        "# - If test_with: 'last' we perform test with the latest model.\n",
        "# - if test_with: 'best, we perform test with the best model (according to the metric specified in test_key)\n",
        "# The variable avg_models can be used to average the parameters of the last (or best) N saved models before testing.\n",
        "# This can have a regularization effect. If avg_models: 1, the last (or best) model is used directly.\n",
        "test_with: 'last' # 'last' or 'best'\n",
        "test_key: \"acc\" # Possible opts: \"loss\", \"f1\", \"auc\", \"acc\"\n",
        "\n",
        "# METRICS\n",
        "f1: !name:sklearn.metrics.f1_score\n",
        "    average: 'macro'\n",
        "acc: !name:sklearn.metrics.balanced_accuracy_score\n",
        "cm: !name:sklearn.metrics.confusion_matrix\n",
        "metrics:\n",
        "    f1: !ref <f1>\n",
        "    acc: !ref <acc>\n",
        "    cm: !ref <cm>\n",
        "\n",
        "# TRAINING HPARS\n",
        "n_train_examples: 100  # it will be replaced in the train script\n",
        "# checkpoints to average\n",
        "avg_models: 10\n",
        "number_of_epochs: 1000\n",
        "lr: 0.0001\n",
        "# Learning rate scheduling (cyclic learning rate is used here)\n",
        "max_lr: !ref <lr> # Upper bound of the cycle (max value of the lr)\n",
        "base_lr: 0.00000001 # Lower bound in the cycle (min value of the lr)\n",
        "step_size_multiplier: 5 #from 2 to 8\n",
        "step_size: !apply:round\n",
        "    - !ref <step_size_multiplier> * <n_train_examples> / <batch_size>\n",
        "lr_annealing: !new:speechbrain.nnet.schedulers.CyclicLRScheduler\n",
        "    base_lr: !ref <base_lr>\n",
        "    max_lr: !ref <max_lr>\n",
        "    step_size: !ref <step_size>\n",
        "label_smoothing: 0.0\n",
        "loss: !name:speechbrain.nnet.losses.nll_loss\n",
        "    label_smoothing: !ref <label_smoothing>\n",
        "optimizer: !name:torch.optim.Adam\n",
        "    lr: !ref <lr>\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter  # epoch counter\n",
        "    limit: !ref <number_of_epochs>\n",
        "batch_size_exponent: 4\n",
        "batch_size: !ref 2 ** <batch_size_exponent>\n",
        "valid_ratio: 0.2\n",
        "\n",
        "# DATA AUGMENTATION\n",
        "# cutcat (disabled when min_num_segments=max_num_segments=1)\n",
        "max_num_segments: 3\n",
        "cutcat: !new:speechbrain.augment.time_domain.CutCat\n",
        "    min_num_segments: 2\n",
        "    max_num_segments: !ref <max_num_segments>\n",
        "# random amplitude gain between 0.5-1.5 uV (disabled when amp_delta=0.)\n",
        "amp_delta: 0.01742\n",
        "rand_amp: !new:speechbrain.augment.time_domain.RandAmp\n",
        "    amp_low: !ref 1 - <amp_delta>\n",
        "    amp_high: !ref 1 + <amp_delta>\n",
        "# random shifts between -300 ms to 300 ms (disabled when shift_delta=0.)\n",
        "shift_delta_: 1\n",
        "shift_delta: !ref 1e-2 * <shift_delta_> # 0.250 # 0.-0.25 with steps of 0.01\n",
        "min_shift: !apply:math.floor\n",
        "    - !ref 0 - <sample_rate> * <shift_delta>\n",
        "max_shift: !apply:math.floor\n",
        "    - !ref 0 + <sample_rate> * <shift_delta>\n",
        "time_shift: !new:speechbrain.augment.freq_domain.RandomShift\n",
        "    min_shift: !ref <min_shift>\n",
        "    max_shift: !ref <max_shift>\n",
        "    dim: 1\n",
        "# injection of gaussian white noise\n",
        "snr_white_low: 15.0\n",
        "snr_white_delta: 19.1\n",
        "snr_white_high: !ref <snr_white_low> + <snr_white_delta>\n",
        "add_noise_white: !new:speechbrain.augment.time_domain.AddNoise\n",
        "    snr_low: !ref <snr_white_low>\n",
        "    snr_high: !ref <snr_white_high>\n",
        "\n",
        "repeat_augment: 1\n",
        "augment: !new:speechbrain.augment.augmenter.Augmenter\n",
        "    parallel_augment: True\n",
        "    concat_original: True\n",
        "    parallel_augment_fixed_bs: True\n",
        "    repeat_augment: !ref <repeat_augment>\n",
        "    shuffle_augmentations: True\n",
        "    min_augmentations: 4\n",
        "    max_augmentations: 4\n",
        "    augmentations: [\n",
        "        !ref <cutcat>,\n",
        "        !ref <rand_amp>,\n",
        "        !ref <time_shift>,\n",
        "        !ref <add_noise_white>]\n",
        "\n",
        "# DATA NORMALIZATION\n",
        "dims_to_normalize: 1 # 1 (time) or 2 (EEG channels)\n",
        "normalize: !name:speechbrain.processing.signal_processing.mean_std_norm\n",
        "    dims: !ref <dims_to_normalize>\n",
        "# MODEL\n",
        "input_shape: [null, !ref <T>, !ref <C>, null]\n",
        "cnn_temporal_kernels: 61\n",
        "cnn_temporal_kernelsize: 51\n",
        "# depth multiplier for the spatial depthwise conv. layer\n",
        "cnn_spatial_depth_multiplier: 4\n",
        "cnn_spatial_max_norm: 1.  # kernel max-norm constaint of the spatial depthwise conv. layer\n",
        "cnn_spatial_pool: 4\n",
        "cnn_septemporal_depth_multiplier: 1  # depth multiplier for the separable temporal conv. layer\n",
        "cnn_septemporal_point_kernels_ratio_: 7\n",
        "cnn_septemporal_point_kernels_ratio: !ref <cnn_septemporal_point_kernels_ratio_> / 4\n",
        "## number of temporal filters in the separable temporal conv. layer\n",
        "cnn_septemporal_point_kernels_: !ref <cnn_temporal_kernels> * <cnn_spatial_depth_multiplier> * <cnn_septemporal_depth_multiplier>\n",
        "cnn_septemporal_point_kernels: !apply:math.ceil\n",
        "    - !ref <cnn_septemporal_point_kernels_ratio> * <cnn_septemporal_point_kernels_> + 1\n",
        "cnn_septemporal_kernelsize_: 15\n",
        "max_cnn_spatial_pool: 4\n",
        "cnn_septemporal_kernelsize: !apply:round\n",
        "    - !ref <cnn_septemporal_kernelsize_> * <max_cnn_spatial_pool> / <cnn_spatial_pool>\n",
        "cnn_septemporal_pool: 7\n",
        "cnn_pool_type: 'avg'\n",
        "dense_max_norm: 0.25  # kernel max-norm constaint of the dense layer\n",
        "dropout: 0.008464\n",
        "activation_type: 'elu'\n",
        "additional_pooling_kernel_size: 2 # @orion_step1: --cnn_temporal_kernels~\"uniform(1, 3,discrete=True)\"\n",
        "\n",
        "model: !new:models.MyEEGNet.MyEEGNet\n",
        "    input_shape: !ref <input_shape>\n",
        "    cnn_temporal_kernels: !ref <cnn_temporal_kernels>\n",
        "    cnn_temporal_kernelsize: [!ref <cnn_temporal_kernelsize>, 1]\n",
        "    cnn_spatial_depth_multiplier: !ref <cnn_spatial_depth_multiplier>\n",
        "    cnn_spatial_max_norm: !ref <cnn_spatial_max_norm>\n",
        "    cnn_spatial_pool: [!ref <cnn_spatial_pool>, 1]\n",
        "    cnn_septemporal_depth_multiplier: !ref <cnn_septemporal_depth_multiplier>\n",
        "    cnn_septemporal_point_kernels: !ref <cnn_septemporal_point_kernels>\n",
        "    cnn_septemporal_kernelsize: [!ref <cnn_septemporal_kernelsize>, 1]\n",
        "    cnn_septemporal_pool: [!ref <cnn_septemporal_pool>, 1]\n",
        "    cnn_pool_type: !ref <cnn_pool_type>\n",
        "    activation_type: !ref <activation_type>\n",
        "    dense_max_norm: !ref <dense_max_norm>\n",
        "    dropout: !ref <dropout>\n",
        "    dense_n_neurons: !ref <n_classes>\n",
        "    additional_pooling_kernel_size: [!ref <additional_pooling_kernel_size>, 1]\n",
        "\"\"\"\n",
        "\n",
        "myYAMLFilePath = \"/content/benchmarks/benchmarks/MOABB/hparams/MotorImagery/BNCI2014001/MyEEGNet.yaml\"\n",
        "\n",
        "# Write the class definition to the file\n",
        "with open(myYAMLFilePath, 'w') as file:\n",
        "    file.write(MyEEGNETYaml)"
      ],
      "metadata": {
        "id": "2Mf_kmwekmnS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "rfPPv120d_de"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filePath=\"/content/benchmarks/benchmarks/MOABB/models/MyEEGNet.py\"\n",
        "fileContent='''\n",
        "import torch\n",
        "import speechbrain as sb\n",
        "\n",
        "class MyEEGNet(torch.nn.Module):\n",
        "    \"\"\"MyEEGNet.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    input_shape: tuple\n",
        "        The shape of the input.\n",
        "    cnn_temporal_kernels: int\n",
        "        Number of kernels in the 2d temporal convolution.\n",
        "    cnn_temporal_kernelsize: tuple\n",
        "        Kernel size of the 2d temporal convolution.\n",
        "    cnn_spatial_depth_multiplier: int\n",
        "        Depth multiplier of the 2d spatial depthwise convolution.\n",
        "    cnn_spatial_max_norm: float\n",
        "        Kernel max norm of the 2d spatial depthwise convolution.\n",
        "    cnn_spatial_pool: tuple\n",
        "        Pool size and stride after the 2d spatial depthwise convolution.\n",
        "    cnn_septemporal_depth_multiplier: int\n",
        "        Depth multiplier of the 2d temporal separable convolution.\n",
        "    cnn_septemporal_kernelsize: tuple\n",
        "        Kernel size of the 2d temporal separable convolution.\n",
        "    cnn_septemporal_pool: tuple\n",
        "        Pool size and stride after the 2d temporal separable convolution.\n",
        "    cnn_pool_type: string\n",
        "        Pooling type.\n",
        "    dropout: float\n",
        "        Dropout probability.\n",
        "    dense_max_norm: float\n",
        "        Weight max norm of the fully-connected layer.\n",
        "    dense_n_neurons: int\n",
        "        Number of output neurons.\n",
        "    activation_type: str\n",
        "        Activation function of the hidden layers.\n",
        "    additional_pooling_kernel_size: tuple, optional\n",
        "        Kernel size for the additional max pooling layer.\n",
        "    Example\n",
        "    -------\n",
        "    #>>> inp_tensor = torch.rand([1, 200, 32, 1])\n",
        "    #>>> model = EEGNet(input_shape=inp_tensor.shape)\n",
        "    #>>> output = model(inp_tensor)\n",
        "    #>>> output.shape\n",
        "    #torch.Size([1,4])\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_shape=None,  # (1, T, C, 1)\n",
        "        cnn_temporal_kernels=8,\n",
        "        cnn_temporal_kernelsize=(33, 1),\n",
        "        cnn_spatial_depth_multiplier=2,\n",
        "        cnn_spatial_max_norm=1.0,\n",
        "        cnn_spatial_pool=(4, 1),\n",
        "        cnn_septemporal_depth_multiplier=1,\n",
        "        cnn_septemporal_point_kernels=None,\n",
        "        cnn_septemporal_kernelsize=(17, 1),\n",
        "        cnn_septemporal_pool=(8, 1),\n",
        "        cnn_pool_type=\"avg\",\n",
        "        dropout=0.5,\n",
        "        dense_max_norm=0.25,\n",
        "        dense_n_neurons=4,\n",
        "        activation_type=\"elu\",\n",
        "        additional_pooling_kernel_size=(2,1)  # Default kernel size for the additional max pooling layer\n",
        "    ):\n",
        "        super().__init__()\n",
        "        if input_shape is None:\n",
        "            raise ValueError(\"Must specify input_shape\")\n",
        "        if activation_type == \"gelu\":\n",
        "            activation = torch.nn.GELU()\n",
        "        elif activation_type == \"elu\":\n",
        "            activation = torch.nn.ELU()\n",
        "        elif activation_type == \"relu\":\n",
        "            activation = torch.nn.ReLU()\n",
        "        elif activation_type == \"leaky_relu\":\n",
        "            activation = torch.nn.LeakyReLU()\n",
        "        elif activation_type == \"prelu\":\n",
        "            activation = torch.nn.PReLU()\n",
        "        else:\n",
        "            raise ValueError(\"Wrong hidden activation function\")\n",
        "        self.default_sf = 128  # sampling rate of the original publication (Hz)\n",
        "        # T = input_shape[1]\n",
        "        C = input_shape[2]\n",
        "\n",
        "        # CONVOLUTIONAL MODULE\n",
        "        self.conv_module = torch.nn.Sequential()\n",
        "        # Temporal convolution\n",
        "        self.conv_module.add_module(\n",
        "            \"conv_0\",\n",
        "            sb.nnet.CNN.Conv2d(\n",
        "                in_channels=1,\n",
        "                out_channels=cnn_temporal_kernels,\n",
        "                kernel_size=cnn_temporal_kernelsize,\n",
        "                padding=\"same\",\n",
        "                padding_mode=\"constant\",\n",
        "                bias=False,\n",
        "                swap=True,\n",
        "            ),\n",
        "        )\n",
        "        self.conv_module.add_module(\n",
        "            \"bnorm_0\",\n",
        "            sb.nnet.normalization.BatchNorm2d(\n",
        "                input_size=cnn_temporal_kernels, momentum=0.01, affine=True,\n",
        "            ),\n",
        "        )\n",
        "        # Spatial depthwise convolution\n",
        "        cnn_spatial_kernels = (\n",
        "            cnn_spatial_depth_multiplier * cnn_temporal_kernels\n",
        "        )\n",
        "        self.conv_module.add_module(\n",
        "            \"conv_1\",\n",
        "            sb.nnet.CNN.Conv2d(\n",
        "                in_channels=cnn_temporal_kernels,\n",
        "                out_channels=cnn_spatial_kernels,\n",
        "                kernel_size=(1, C),\n",
        "                groups=cnn_temporal_kernels,\n",
        "                padding=\"valid\",\n",
        "                bias=False,\n",
        "                max_norm=cnn_spatial_max_norm,\n",
        "                swap=True,\n",
        "            ),\n",
        "        )\n",
        "        self.conv_module.add_module(\n",
        "            \"bnorm_1\",\n",
        "            sb.nnet.normalization.BatchNorm2d(\n",
        "                input_size=cnn_spatial_kernels, momentum=0.01, affine=True,\n",
        "            ),\n",
        "        )\n",
        "        self.conv_module.add_module(\"act_1\", activation)\n",
        "        self.conv_module.add_module(\n",
        "            \"pool_1\",\n",
        "            sb.nnet.pooling.Pooling2d(\n",
        "                pool_type=cnn_pool_type,\n",
        "                kernel_size=cnn_spatial_pool,\n",
        "                stride=cnn_spatial_pool,\n",
        "                pool_axis=[1, 2],\n",
        "            ),\n",
        "        )\n",
        "        self.conv_module.add_module(\"dropout_1\", torch.nn.Dropout(p=dropout))\n",
        "\n",
        "        # Temporal separable convolution\n",
        "        cnn_septemporal_kernels = (\n",
        "            cnn_spatial_kernels * cnn_septemporal_depth_multiplier\n",
        "        )\n",
        "        self.conv_module.add_module(\n",
        "            \"conv_2\",\n",
        "            sb.nnet.CNN.Conv2d(\n",
        "                in_channels=cnn_spatial_kernels,\n",
        "                out_channels=cnn_septemporal_kernels,\n",
        "                kernel_size=cnn_septemporal_kernelsize,\n",
        "                groups=cnn_spatial_kernels,\n",
        "                padding=\"same\",\n",
        "                padding_mode=\"constant\",\n",
        "                bias=False,\n",
        "                swap=True,\n",
        "            ),\n",
        "        )\n",
        "\n",
        "        if cnn_septemporal_point_kernels is None:\n",
        "            cnn_septemporal_point_kernels = cnn_septemporal_kernels\n",
        "\n",
        "        self.conv_module.add_module(\n",
        "            \"conv_3\",\n",
        "            sb.nnet.CNN.Conv2d(\n",
        "                in_channels=cnn_septemporal_kernels,\n",
        "                out_channels=cnn_septemporal_point_kernels,\n",
        "                kernel_size=(1, 1),\n",
        "                padding=\"valid\",\n",
        "                bias=False,\n",
        "                swap=True,\n",
        "            ),\n",
        "        )\n",
        "        self.conv_module.add_module(\n",
        "            \"bnorm_3\",\n",
        "            sb.nnet.normalization.BatchNorm2d(\n",
        "                input_size=cnn_septemporal_point_kernels,\n",
        "                momentum=0.01,\n",
        "                affine=True,\n",
        "            ),\n",
        "        )\n",
        "        self.conv_module.add_module(\"act_3\", activation)\n",
        "        self.conv_module.add_module(\n",
        "            \"pool_3\",\n",
        "            sb.nnet.pooling.Pooling2d(\n",
        "                pool_type=cnn_pool_type,\n",
        "                kernel_size=cnn_septemporal_pool,\n",
        "                stride=cnn_septemporal_pool,\n",
        "                pool_axis=[1, 2],\n",
        "            ),\n",
        "        )\n",
        "        self.conv_module.add_module(\"dropout_3\", torch.nn.Dropout(p=dropout))\n",
        "\n",
        "        # **NEW** additional pooling layer after the last convolution\n",
        "        # Added Max Pooling to highlight the important feature\n",
        "        self.conv_module.add_module(\n",
        "        \"ADDITIONAL_POOL\",\n",
        "        sb.nnet.pooling.Pooling2d(\n",
        "            pool_type='max',  # Changed to max pooling\n",
        "            kernel_size=additional_pooling_kernel_size,\n",
        "            stride=(2,1),\n",
        "            pool_axis=[1,2],\n",
        "        ),\n",
        "       )\n",
        "\n",
        "        # Shape of intermediate feature maps\n",
        "        out = self.conv_module(\n",
        "            torch.ones((1,) + tuple(input_shape[1:-1]) + (1,))\n",
        "        )\n",
        "        dense_input_size = self._num_flat_features(out)\n",
        "        # DENSE MODULE\n",
        "        self.dense_module = torch.nn.Sequential()\n",
        "        self.dense_module.add_module(\n",
        "            \"flatten\", torch.nn.Flatten(),\n",
        "        )\n",
        "        self.dense_module.add_module(\n",
        "            \"fc_out\",\n",
        "            sb.nnet.linear.Linear(\n",
        "                input_size=dense_input_size,\n",
        "                n_neurons=dense_n_neurons,\n",
        "                max_norm=dense_max_norm,\n",
        "            ),\n",
        "        )\n",
        "        self.dense_module.add_module(\"act_out\", torch.nn.LogSoftmax(dim=1))\n",
        "\n",
        "    def _num_flat_features(self, x):\n",
        "        \"\"\"Returns the number of flattened features from a tensor.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        x : torch.Tensor\n",
        "            Input feature map.\n",
        "        \"\"\"\n",
        "\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Returns the output of the model.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        x : torch.Tensor (batch, time, EEG channel, channel)\n",
        "            Input to convolve. 4d tensors are expected.\n",
        "        \"\"\"\n",
        "        x = self.conv_module(x)\n",
        "        x = self.dense_module(x)\n",
        "        return x\n",
        "'''\n",
        "\n",
        "# Write the class definition to the file\n",
        "with open(filePath, 'w') as file:\n",
        "    file.write(fileContent)"
      ],
      "metadata": {
        "id": "px0zgVm2d_Ec"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters Training"
      ],
      "metadata": {
        "id": "BIXI_X_asp0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/benchmarks/benchmarks/MOABB/'\n",
        "\n",
        "!./run_hparam_optimization.sh --hparams 'hparams/MotorImagery/BNCI2014001/MyEEGNet.yaml' \\\n",
        "--data_folder '/content/data/BNCI2014001'\\\n",
        "--cached_data_folder '/content/data' \\\n",
        "--output_folder '/content/results/hyperparameter-search/BNCI2014001' \\\n",
        "--nsbj 9 --nsess 2 --nruns 1 --train_mode 'leave-one-session-out' \\\n",
        "--exp_name 'hyperparameter-search' \\\n",
        "--nsbj_hpsearch 3 --nsess_hpsearch 2 \\\n",
        "--nruns_eval 1 \\\n",
        "--eval_metric acc \\\n",
        "--exp_max_trials 5 \\\n",
        "--number_of_epochs 100 \\"
      ],
      "metadata": {
        "id": "jF280_TpssW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "6fN4EccxCtKH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/benchmarks/benchmarks/MOABB'\n",
        "\n",
        "!./run_experiments.sh \\\n",
        "--hparams hparams/MotorImagery/BNCI2014001/MyEEGNet.yaml \\\n",
        "--data_folder eeg_data \\\n",
        "--output_folder results/MotorImagery/BNCI2014001/MyEEGNet \\\n",
        "--nsbj 9 \\\n",
        "--nsess 2 \\\n",
        "--nruns 1 \\\n",
        "--train_mode leave-one-session-out \\\n",
        "--device=cuda"
      ],
      "metadata": {
        "id": "spNVRqFiILMc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6KqzvfI3FNqg",
        "_gBZbREAFPl9",
        "TkTlAzR-FSgb",
        "dxGSDZo_FWVh"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "6KqzvfI3FNqg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kaHCoJXZtIrz"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/speechbrain/benchmarks\n",
        "%cd /content/benchmarks\n",
        "!git checkout eeg\n",
        "\n",
        "%cd /content/benchmarks/benchmarks/MOABB\n",
        "!pip install -r extra-requirements.txt # Install additional dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "# Clone SpeechBrain repository (development branch)\n",
        "%cd /content/\n",
        "!git clone https://github.com/speechbrain/speechbrain/\n",
        "%cd /content/speechbrain/\n",
        "\n",
        "# Install required dependencies\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "# Install SpeechBrain in editable mode\n",
        "!pip install -e .\n",
        "\n",
        "%cd /content/"
      ],
      "metadata": {
        "id": "11L12CY5tXpg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# YAML"
      ],
      "metadata": {
        "id": "_gBZbREAFPl9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MyVanillaNeuralNetworkYAML = \"\"\"\n",
        "seed: 1234\n",
        "__set_torchseed: !apply:torch.manual_seed [!ref <seed>]\n",
        "\n",
        "# DIRECTORIES\n",
        "data_folder: !PLACEHOLDER  #'/path/to/dataset'. The dataset will be automatically downloaded in this folder\n",
        "cached_data_folder: !PLACEHOLDER #'path/to/pickled/dataset'\n",
        "output_folder: !PLACEHOLDER #'path/to/results'\n",
        "\n",
        "# DATASET HPARS\n",
        "dataset: !new:moabb.datasets.BNCI2014001\n",
        "save_prepared_dataset: True\n",
        "data_iterator_name: !PLACEHOLDER\n",
        "target_subject_idx: !PLACEHOLDER\n",
        "target_session_idx: !PLACEHOLDER\n",
        "events_to_load: null\n",
        "original_sample_rate: 250\n",
        "sample_rate: 125\n",
        "fmin: 0.13\n",
        "fmax: 46.0\n",
        "n_classes: 4\n",
        "tmin: 0.\n",
        "tmax: 4.0\n",
        "n_steps_channel_selection: 2\n",
        "T: !apply:math.ceil\n",
        "    - !ref <sample_rate> * (<tmax> - <tmin>)\n",
        "C: 22\n",
        "test_with: 'last'\n",
        "test_key: \"acc\"\n",
        "\n",
        "# METRICS\n",
        "f1: !name:sklearn.metrics.f1_score\n",
        "    average: 'macro'\n",
        "acc: !name:sklearn.metrics.balanced_accuracy_score\n",
        "cm: !name:sklearn.metrics.confusion_matrix\n",
        "metrics:\n",
        "    f1: !ref <f1>\n",
        "    acc: !ref <acc>\n",
        "    cm: !ref <cm>\n",
        "\n",
        "# TRAINING HPARS\n",
        "n_train_examples: 1000\n",
        "avg_models: 10\n",
        "number_of_epochs: 1000\n",
        "lr: 0.005\n",
        "max_lr: !ref <lr>\n",
        "base_lr: 0.00000001\n",
        "step_size_multiplier: 5\n",
        "step_size: !apply:round\n",
        "    - !ref <step_size_multiplier> * <n_train_examples> / <batch_size>\n",
        "lr_annealing: !new:speechbrain.nnet.schedulers.CyclicLRScheduler\n",
        "    base_lr: !ref <base_lr>\n",
        "    max_lr: !ref <max_lr>\n",
        "    step_size: !ref <step_size>\n",
        "label_smoothing: 0.0\n",
        "loss: !name:speechbrain.nnet.losses.nll_loss\n",
        "    label_smoothing: !ref <label_smoothing>\n",
        "optimizer: !name:torch.optim.Adam\n",
        "    lr: !ref <lr>\n",
        "epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter\n",
        "    limit: !ref <number_of_epochs>\n",
        "batch_size_exponent: 4\n",
        "batch_size: !ref 2 ** <batch_size_exponent>\n",
        "valid_ratio: 0.2\n",
        "\n",
        "# DATA AUGMENTATION\n",
        "max_num_segments: 3\n",
        "cutcat: !new:speechbrain.augment.time_domain.CutCat\n",
        "    min_num_segments: 2\n",
        "    max_num_segments: !ref <max_num_segments>\n",
        "amp_delta: 0.01742\n",
        "rand_amp: !new:speechbrain.augment.time_domain.RandAmp\n",
        "    amp_low: !ref 1 - <amp_delta>\n",
        "    amp_high: !ref 1 + <amp_delta>\n",
        "shift_delta_: 1\n",
        "shift_delta: !ref 1e-2 * <shift_delta_>\n",
        "min_shift: !apply:math.floor\n",
        "    - !ref 0 - <sample_rate> * <shift_delta>\n",
        "max_shift: !apply:math.floor\n",
        "    - !ref 0 + <sample_rate> * <shift_delta>\n",
        "time_shift: !new:speechbrain.augment.freq_domain.RandomShift\n",
        "    min_shift: !ref <min_shift>\n",
        "    max_shift: !ref <max_shift>\n",
        "    dim: 1\n",
        "snr_white_low: 15.0\n",
        "snr_white_delta: 19.1\n",
        "snr_white_high: !ref <snr_white_low> + <snr_white_delta>\n",
        "add_noise_white: !new:speechbrain.augment.time_domain.AddNoise\n",
        "    snr_low: !ref <snr_white_low>\n",
        "    snr_high: !ref <snr_white_high>\n",
        "repeat_augment: 1\n",
        "augment: !new:speechbrain.augment.augmenter.Augmenter\n",
        "    parallel_augment: True\n",
        "    concat_original: True\n",
        "    parallel_augment_fixed_bs: True\n",
        "    repeat_augment: !ref <repeat_augment>\n",
        "    shuffle_augmentations: True\n",
        "    min_augmentations: 4\n",
        "    max_augmentations: 4\n",
        "    augmentations: [\n",
        "        !ref <cutcat>,\n",
        "        !ref <rand_amp>,\n",
        "        !ref <time_shift>,\n",
        "        !ref <add_noise_white>]\n",
        "\n",
        "# DATA NORMALIZATION\n",
        "dims_to_normalize: 1\n",
        "normalize: !name:speechbrain.processing.signal_processing.mean_std_norm\n",
        "    dims: !ref <dims_to_normalize>\n",
        "\n",
        "# MODEL\n",
        "input_shape: [1, !ref <T>, !ref <C>, 1]\n",
        "activation_type: 'prelu' # @orion_step1: --activation_type~\"choices(['prelu','relu','leaky_relu','gelu','elu'])\"\n",
        "hidden_layers: [64,32]\n",
        "dropout: 0.4\n",
        "\n",
        "model: !new:models.MyVanillaNeuralNet.MyVanillaNeuralNet\n",
        "    input_shape: !ref <input_shape>\n",
        "    hidden_layers: !ref <hidden_layers>\n",
        "    activation_type: !ref <activation_type>\n",
        "    dropout: !ref <dropout>\n",
        "    n_neurons: !ref <n_classes>\n",
        "\"\"\"\n",
        "\n",
        "myYAMLFilePath = \"/content/benchmarks/benchmarks/MOABB/hparams/MotorImagery/BNCI2014001/MyVanillaNeuralNet.yaml\"\n",
        "\n",
        "# Write the class definition to the file\n",
        "with open(myYAMLFilePath, 'w') as file:\n",
        "    file.write(MyVanillaNeuralNetworkYAML)"
      ],
      "metadata": {
        "id": "-vDci8E9Apmg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "TkTlAzR-FSgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filePath=\"/content/benchmarks/benchmarks/MOABB/models/MyVanillaNeuralNet.py\"\n",
        "fileContent = '''\n",
        "import torch\n",
        "import speechbrain as sb\n",
        "\n",
        "class MyVanillaNeuralNet(torch.nn.Module):\n",
        "    \"\"\"MyVanillaNeuralNet.\n",
        "\n",
        "    A vanilla neural network (fully connected neural network) for EEG data classification.\n",
        "\n",
        "    Arguments\n",
        "    ---------\n",
        "    input_shape : tuple\n",
        "        The shape of the input tensor (batch, time, EEG channel, channel).\n",
        "    hidden_layers : list of int\n",
        "        A list specifying the number of neurons in each hidden layer.\n",
        "    activation_type: str\n",
        "        Activation function of the hidden layers.\n",
        "    dropout : float\n",
        "        Dropout probability.\n",
        "    n_neurons : int\n",
        "        Number of output neurons (classes).\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> inp_tensor = torch.rand([1, 200, 32, 1])\n",
        "    >>> model = VanillaNeuralNet(input_shape=inp_tensor.shape, hidden_layers=[128, 64], activation=\"relu\",dropout=0.5, n_neurons=4)\n",
        "    >>> output = model(inp_tensor)\n",
        "    >>> output.shape\n",
        "    torch.Size([1, 4])\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_shape=None,\n",
        "        hidden_layers=[128, 64],\n",
        "        activation_type=\"relu\",\n",
        "        dropout=0.5,\n",
        "        n_neurons=4,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        if input_shape is None:\n",
        "            raise ValueError(\"Must specify input_shape\")\n",
        "\n",
        "        # Flatten input shape to calculate input features for fully connected layers\n",
        "        self.input_features = input_shape[1] * input_shape[2] * input_shape[3]\n",
        "\n",
        "        # Create a list of layers\n",
        "        layers = []\n",
        "        if activation_type == \"gelu\":\n",
        "            activation = torch.nn.GELU()\n",
        "        elif activation_type == \"elu\":\n",
        "            activation = torch.nn.ELU()\n",
        "        elif activation_type == \"relu\":\n",
        "            activation = torch.nn.ReLU()\n",
        "        elif activation_type == \"leaky_relu\":\n",
        "            activation = torch.nn.LeakyReLU()\n",
        "        elif activation_type == \"prelu\":\n",
        "            activation = torch.nn.PReLU()\n",
        "\n",
        "        # Add hidden layers\n",
        "        for i, hidden_units in enumerate(hidden_layers):\n",
        "            if i == 0:\n",
        "                # First layer\n",
        "                layers.append(torch.nn.Linear(self.input_features, hidden_units))\n",
        "            else:\n",
        "                # Subsequent layers\n",
        "                layers.append(torch.nn.Linear(hidden_layers[i - 1], hidden_units))\n",
        "\n",
        "            # Add activation function\n",
        "            layers.append(activation)\n",
        "\n",
        "            # Add dropout\n",
        "            layers.append(torch.nn.Dropout(dropout))\n",
        "\n",
        "        # Add output layer\n",
        "        layers.append(torch.nn.Linear(hidden_layers[-1], n_neurons))\n",
        "\n",
        "        # Add softmax activation function\n",
        "        layers.append(torch.nn.LogSoftmax(dim=1))\n",
        "\n",
        "        # Define the layers as a sequential module\n",
        "        self.layers = torch.nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward pass of the model.\n",
        "\n",
        "        Arguments\n",
        "        ---------\n",
        "        x : torch.Tensor\n",
        "            Input EEG tensor with shape (batch, time, EEG channel, channel).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        predictions : torch.Tensor\n",
        "            Model predictions.\n",
        "        \"\"\"\n",
        "        # Flatten input tensor\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Pass the input through the fully connected layers\n",
        "        x = self.layers(x)\n",
        "\n",
        "        return x\n",
        "'''\n",
        "# Write the class definition to the file\n",
        "with open(filePath, 'w') as file:\n",
        "    file.write(fileContent)"
      ],
      "metadata": {
        "id": "K2ghQ8cC_rJq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters Training"
      ],
      "metadata": {
        "id": "xtLl8YDQFUEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/benchmarks/benchmarks/MOABB/'\n",
        "\n",
        "!./run_hparam_optimization.sh --hparams 'hparams/MotorImagery/BNCI2014001/MyVanillaNeuralNet.yaml' \\\n",
        "--data_folder '/content/data/BNCI2014001'\\\n",
        "--cached_data_folder '/content/data' \\\n",
        "--output_folder '/content/results/hyperparameter-search/BNCI2014001' \\\n",
        "--nsbj 9 --nsess 2 --nruns 1 --train_mode 'leave-one-session-out' \\\n",
        "--exp_name 'hyperparameter-search2' \\\n",
        "--nsbj_hpsearch 3 --nsess_hpsearch 2 \\\n",
        "--nruns_eval 1 \\\n",
        "--eval_metric acc \\\n",
        "--exp_max_trials 5 \\\n",
        "--number_of_epochs 100 \\"
      ],
      "metadata": {
        "id": "1VT4dp03Ki_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "dxGSDZo_FWVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd '/content/benchmarks/benchmarks/MOABB/'\n",
        "\n",
        "!./run_experiments.sh \\\n",
        "--hparams hparams/MotorImagery/BNCI2014001/MyVanillaNeuralNet.yaml \\\n",
        "--data_folder eeg_data \\\n",
        "--output_folder results/MotorImagery/BNCI2014001/MyVanillaNeuralNet \\\n",
        "--nsbj 9 \\\n",
        "--nsess 2 \\\n",
        "--nruns 1 \\\n",
        "--train_mode leave-one-session-out \\\n",
        "--device=cuda"
      ],
      "metadata": {
        "id": "F8cWuVvNDH17"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}